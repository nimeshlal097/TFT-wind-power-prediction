{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPxiqR1HkAaWdG/TCs+X4vq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nimeshlal097/TFT-wind-power-prediction/blob/main/Test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B67rsXx5fBrU",
        "outputId": "0649e47b-207c-47b3-c72f-d297c19c5d37"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: Seed set to 42\n",
            "INFO:lightning.fabric.utilities.seed:Seed set to 42\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "42"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "import warnings\n",
        "import kagglehub\n",
        "from datetime import timedelta\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_absolute_percentage_error, r2_score, mean_squared_error\n",
        "import lightning.pytorch as pl # Changed from pytorch_lightning as pl\n",
        "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from pytorch_lightning.loggers import CSVLogger\n",
        "from pytorch_forecasting import TimeSeriesDataSet, TemporalFusionTransformer\n",
        "from pytorch_forecasting.data import GroupNormalizer\n",
        "from pytorch_forecasting.metrics import QuantileLoss, MAE, RMSE\n",
        "import torch\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "pl.seed_everything(42)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = kagglehub.dataset_download(\"mubashirrahim/wind-power-generation-data-forecasting\")\n",
        "data = pd.read_csv(path + \"/Location1.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ELVvDlukff0O",
        "outputId": "2af26c00-299e-4ab9-b94f-87a660e14827"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Colab cache for faster access to the 'wind-power-generation-data-forecasting' dataset.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Parse time column\n",
        "data['Time'] = pd.to_datetime(data['Time'])\n",
        "data = data.sort_values('Time').reset_index(drop=True)\n",
        "\n",
        "# Handle missing values\n",
        "data = data.ffill().bfill()\n",
        "\n",
        "print(\"Data Shape:\", data.shape)\n",
        "print(\"\\nFirst few rows:\")\n",
        "print(data.head())\n",
        "print(\"\\nData Info:\")\n",
        "print(data.info())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4IVa5mcFhU7w",
        "outputId": "786c7fb6-9900-44e6-8ffc-920e83cde61c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data Shape: (43800, 10)\n",
            "\n",
            "First few rows:\n",
            "                 Time  temperature_2m  relativehumidity_2m  dewpoint_2m  \\\n",
            "0 2017-01-02 00:00:00            28.5                   85         24.5   \n",
            "1 2017-01-02 01:00:00            28.4                   86         24.7   \n",
            "2 2017-01-02 02:00:00            26.8                   91         24.5   \n",
            "3 2017-01-02 03:00:00            27.4                   88         24.3   \n",
            "4 2017-01-02 04:00:00            27.3                   88         24.1   \n",
            "\n",
            "   windspeed_10m  windspeed_100m  winddirection_10m  winddirection_100m  \\\n",
            "0           1.44            1.26                146                 162   \n",
            "1           2.06            3.99                151                 158   \n",
            "2           1.30            2.78                148                 150   \n",
            "3           1.30            2.69                 58                 105   \n",
            "4           2.47            4.43                 58                  84   \n",
            "\n",
            "   windgusts_10m   Power  \n",
            "0            1.4  0.1635  \n",
            "1            4.4  0.1424  \n",
            "2            3.2  0.1214  \n",
            "3            1.6  0.1003  \n",
            "4            4.0  0.0793  \n",
            "\n",
            "Data Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 43800 entries, 0 to 43799\n",
            "Data columns (total 10 columns):\n",
            " #   Column               Non-Null Count  Dtype         \n",
            "---  ------               --------------  -----         \n",
            " 0   Time                 43800 non-null  datetime64[ns]\n",
            " 1   temperature_2m       43800 non-null  float64       \n",
            " 2   relativehumidity_2m  43800 non-null  int64         \n",
            " 3   dewpoint_2m          43800 non-null  float64       \n",
            " 4   windspeed_10m        43800 non-null  float64       \n",
            " 5   windspeed_100m       43800 non-null  float64       \n",
            " 6   winddirection_10m    43800 non-null  int64         \n",
            " 7   winddirection_100m   43800 non-null  int64         \n",
            " 8   windgusts_10m        43800 non-null  float64       \n",
            " 9   Power                43800 non-null  float64       \n",
            "dtypes: datetime64[ns](1), float64(6), int64(3)\n",
            "memory usage: 3.3 MB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Hour cyclic features\n",
        "data['hour'] = data['Time'].dt.hour\n",
        "data['hour_sin'] = np.sin(2 * np.pi * data['hour'] / 24)\n",
        "data['hour_cos'] = np.cos(2 * np.pi * data['hour'] / 24)\n",
        "\n",
        "# Month cyclic features\n",
        "data['month'] = data['Time'].dt.month\n",
        "data['month_sin'] = np.sin(2 * np.pi * data['month'] / 12)\n",
        "data['month_cos'] = np.cos(2 * np.pi * data['month'] / 12)\n",
        "\n",
        "# Day of week cyclic features\n",
        "data['dayofweek'] = data['Time'].dt.dayofweek\n",
        "data['dayofweek_sin'] = np.sin(2 * np.pi * data['dayofweek'] / 7)\n",
        "data['dayofweek_cos'] = np.cos(2 * np.pi * data['dayofweek'] / 7)\n",
        "\n",
        "print(\"Cyclic features added!\")\n",
        "print(f\"Columns now: {len(data.columns)}\")\n",
        "print(data.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hIHpeTQdhW4A",
        "outputId": "c95b3a49-cf2d-412b-b8ef-52f59e10f124"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cyclic features added!\n",
            "Columns now: 19\n",
            "                 Time  temperature_2m  relativehumidity_2m  dewpoint_2m  \\\n",
            "0 2017-01-02 00:00:00            28.5                   85         24.5   \n",
            "1 2017-01-02 01:00:00            28.4                   86         24.7   \n",
            "2 2017-01-02 02:00:00            26.8                   91         24.5   \n",
            "3 2017-01-02 03:00:00            27.4                   88         24.3   \n",
            "4 2017-01-02 04:00:00            27.3                   88         24.1   \n",
            "\n",
            "   windspeed_10m  windspeed_100m  winddirection_10m  winddirection_100m  \\\n",
            "0           1.44            1.26                146                 162   \n",
            "1           2.06            3.99                151                 158   \n",
            "2           1.30            2.78                148                 150   \n",
            "3           1.30            2.69                 58                 105   \n",
            "4           2.47            4.43                 58                  84   \n",
            "\n",
            "   windgusts_10m   Power  hour  hour_sin  hour_cos  month  month_sin  \\\n",
            "0            1.4  0.1635     0  0.000000  1.000000      1        0.5   \n",
            "1            4.4  0.1424     1  0.258819  0.965926      1        0.5   \n",
            "2            3.2  0.1214     2  0.500000  0.866025      1        0.5   \n",
            "3            1.6  0.1003     3  0.707107  0.707107      1        0.5   \n",
            "4            4.0  0.0793     4  0.866025  0.500000      1        0.5   \n",
            "\n",
            "   month_cos  dayofweek  dayofweek_sin  dayofweek_cos  \n",
            "0   0.866025          0            0.0            1.0  \n",
            "1   0.866025          0            0.0            1.0  \n",
            "2   0.866025          0            0.0            1.0  \n",
            "3   0.866025          0            0.0            1.0  \n",
            "4   0.866025          0            0.0            1.0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "761af7a5"
      },
      "source": [
        "### CELL 3: ADD LAG FEATURES"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "56394590",
        "outputId": "023042ff-4e31-4870-c598-402e38ff895f"
      },
      "source": [
        "lags = [1, 2, 6, 12, 24, 48]\n",
        "\n",
        "for lag in lags:\n",
        "    data[f'windspeed_100m_lag{lag}'] = data['windspeed_100m'].shift(lag)\n",
        "    data[f'Power_lag{lag}'] = data['Power'].shift(lag)\n",
        "\n",
        "print(\"Lag features added!\")\n",
        "print(f\"New columns: {[col for col in data.columns if 'lag' in col]}\")\n",
        "print(f\"Total columns: {len(data.columns)}\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lag features added!\n",
            "New columns: ['windspeed_100m_lag1', 'Power_lag1', 'windspeed_100m_lag2', 'Power_lag2', 'windspeed_100m_lag6', 'Power_lag6', 'windspeed_100m_lag12', 'Power_lag12', 'windspeed_100m_lag24', 'Power_lag24', 'windspeed_100m_lag48', 'Power_lag48']\n",
            "Total columns: 31\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2b94ac88"
      },
      "source": [
        "### CELL 4: ADD ROLLING FEATURES"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3f9c85ef",
        "outputId": "716a928f-02f2-4207-e3a6-500ed424ce4d"
      },
      "source": [
        "windows = [6, 12, 24]\n",
        "\n",
        "for window in windows:\n",
        "    data[f'windspeed_100m_roll_mean_{window}'] = data['windspeed_100m'].rolling(window).mean()\n",
        "    data[f'windspeed_100m_roll_std_{window}'] = data['windspeed_100m'].rolling(window).std()\n",
        "    data[f'Power_roll_mean_{window}'] = data['Power'].rolling(window).mean()\n",
        "\n",
        "print(\"Rolling features added!\")\n",
        "print(f\"Rolling feature columns: {[col for col in data.columns if 'roll' in col]}\")\n",
        "\n",
        "# Drop NaN rows\n",
        "data = data.dropna().reset_index(drop=True)\n",
        "\n",
        "print(f\"\\nFinal data shape: {data.shape}\")\n",
        "print(data.head())"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rolling features added!\n",
            "Rolling feature columns: ['windspeed_100m_roll_mean_6', 'windspeed_100m_roll_std_6', 'Power_roll_mean_6', 'windspeed_100m_roll_mean_12', 'windspeed_100m_roll_std_12', 'Power_roll_mean_12', 'windspeed_100m_roll_mean_24', 'windspeed_100m_roll_std_24', 'Power_roll_mean_24']\n",
            "\n",
            "Final data shape: (43752, 40)\n",
            "                 Time  temperature_2m  relativehumidity_2m  dewpoint_2m  \\\n",
            "0 2017-01-04 00:00:00            33.7                   95         32.3   \n",
            "1 2017-01-04 01:00:00            32.6                   95         31.2   \n",
            "2 2017-01-04 02:00:00            32.3                   93         30.6   \n",
            "3 2017-01-04 03:00:00            31.9                   91         29.4   \n",
            "4 2017-01-04 04:00:00            28.7                   88         25.5   \n",
            "\n",
            "   windspeed_10m  windspeed_100m  winddirection_10m  winddirection_100m  \\\n",
            "0           4.84            8.32                288                 290   \n",
            "1           5.95           10.11                278                 279   \n",
            "2           5.85            9.93                278                 279   \n",
            "3           7.26           11.81                277                 278   \n",
            "4           7.41           11.93                272                 274   \n",
            "\n",
            "   windgusts_10m   Power  ...  Power_lag48  windspeed_100m_roll_mean_6  \\\n",
            "0           12.1  0.6504  ...       0.1635                    7.258333   \n",
            "1           11.7  0.7103  ...       0.1424                    8.023333   \n",
            "2           12.0  0.7702  ...       0.1214                    8.768333   \n",
            "3           14.2  0.8301  ...       0.1003                    9.786667   \n",
            "4           14.9  0.8900  ...       0.0793                   10.418333   \n",
            "\n",
            "   windspeed_100m_roll_std_6  Power_roll_mean_6  windspeed_100m_roll_mean_12  \\\n",
            "0                   2.025916           0.500600                     5.482500   \n",
            "1                   2.103356           0.560517                     6.200833   \n",
            "2                   1.780735           0.620433                     6.845000   \n",
            "3                   1.376236           0.680350                     7.545000   \n",
            "4                   1.338543           0.740250                     8.132500   \n",
            "\n",
            "   windspeed_100m_roll_std_12  Power_roll_mean_12  \\\n",
            "0                    2.554583            0.368667   \n",
            "1                    2.541769            0.411367   \n",
            "2                    2.411848            0.457892   \n",
            "3                    2.539848            0.508242   \n",
            "4                    2.678928            0.562417   \n",
            "\n",
            "   windspeed_100m_roll_mean_24  windspeed_100m_roll_std_24  Power_roll_mean_24  \n",
            "0                     4.461667                    2.238879            0.249938  \n",
            "1                     4.642500                    2.508216            0.272954  \n",
            "2                     4.915000                    2.713118            0.299408  \n",
            "3                     5.306250                    2.999604            0.329300  \n",
            "4                     5.735417                    3.182043            0.362629  \n",
            "\n",
            "[5 rows x 40 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45a2f5d5"
      },
      "source": [
        "### CELL 5: NORMALIZE DATA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9c135733",
        "outputId": "f1c67562-d241-4393-faaa-8a9f2783c801"
      },
      "source": [
        "numeric_cols = data.select_dtypes(include=[np.number]).columns.tolist()\n",
        "\n",
        "print(f\"Numeric columns: {numeric_cols}\")\n",
        "print(f\"Total numeric columns: {len(numeric_cols)}\")\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "data[numeric_cols] = scaler.fit_transform(data[numeric_cols])\n",
        "\n",
        "print(\"\\nData normalized!\")\n",
        "print(data.head())\n",
        "print(\"\\nNormalized data statistics:\")\n",
        "print(data[numeric_cols].describe())"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Numeric columns: ['temperature_2m', 'relativehumidity_2m', 'dewpoint_2m', 'windspeed_10m', 'windspeed_100m', 'winddirection_10m', 'winddirection_100m', 'windgusts_10m', 'Power', 'hour', 'hour_sin', 'hour_cos', 'month', 'month_sin', 'month_cos', 'dayofweek', 'dayofweek_sin', 'dayofweek_cos', 'windspeed_100m_lag1', 'Power_lag1', 'windspeed_100m_lag2', 'Power_lag2', 'windspeed_100m_lag6', 'Power_lag6', 'windspeed_100m_lag12', 'Power_lag12', 'windspeed_100m_lag24', 'Power_lag24', 'windspeed_100m_lag48', 'Power_lag48', 'windspeed_100m_roll_mean_6', 'windspeed_100m_roll_std_6', 'Power_roll_mean_6', 'windspeed_100m_roll_mean_12', 'windspeed_100m_roll_std_12', 'Power_roll_mean_12', 'windspeed_100m_roll_mean_24', 'windspeed_100m_roll_std_24', 'Power_roll_mean_24']\n",
            "Total numeric columns: 39\n",
            "\n",
            "Data normalized!\n",
            "                 Time  temperature_2m  relativehumidity_2m  dewpoint_2m  \\\n",
            "0 2017-01-04 00:00:00        0.443318             0.939024     0.528908   \n",
            "1 2017-01-04 01:00:00        0.433180             0.939024     0.517131   \n",
            "2 2017-01-04 02:00:00        0.430415             0.914634     0.510707   \n",
            "3 2017-01-04 03:00:00        0.426728             0.890244     0.497859   \n",
            "4 2017-01-04 04:00:00        0.397235             0.853659     0.456103   \n",
            "\n",
            "   windspeed_10m  windspeed_100m  winddirection_10m  winddirection_100m  \\\n",
            "0       0.359851        0.400000           0.799443            0.805556   \n",
            "1       0.442379        0.487105           0.771588            0.775000   \n",
            "2       0.434944        0.478345           0.771588            0.775000   \n",
            "3       0.539777        0.569830           0.768802            0.772222   \n",
            "4       0.550929        0.575669           0.754875            0.761111   \n",
            "\n",
            "   windgusts_10m     Power  ...  Power_lag48  windspeed_100m_roll_mean_6  \\\n",
            "0       0.404181  0.656108  ...     0.164935                    0.350144   \n",
            "1       0.390244  0.716534  ...     0.143650                    0.390123   \n",
            "2       0.400697  0.776960  ...     0.122465                    0.429057   \n",
            "3       0.477352  0.837385  ...     0.101180                    0.482275   \n",
            "4       0.501742  0.897811  ...     0.079996                    0.515286   \n",
            "\n",
            "   windspeed_100m_roll_std_6  Power_roll_mean_6  windspeed_100m_roll_mean_12  \\\n",
            "0                   0.341574           0.505469                     0.284438   \n",
            "1                   0.354737           0.565969                     0.328434   \n",
            "2                   0.299897           0.626468                     0.367886   \n",
            "3                   0.231141           0.686968                     0.410759   \n",
            "4                   0.224733           0.747450                     0.446741   \n",
            "\n",
            "   windspeed_100m_roll_std_12  Power_roll_mean_12  \\\n",
            "0                    0.443246            0.372953   \n",
            "1                    0.440897            0.416149   \n",
            "2                    0.417088            0.463215   \n",
            "3                    0.440545            0.514150   \n",
            "4                    0.466033            0.568955   \n",
            "\n",
            "   windspeed_100m_roll_mean_24  windspeed_100m_roll_std_24  Power_roll_mean_24  \n",
            "0                     0.208775                    0.359729            0.256501  \n",
            "1                     0.221236                    0.408914            0.280122  \n",
            "2                     0.240015                    0.446332            0.307271  \n",
            "3                     0.266977                    0.498649            0.337947  \n",
            "4                     0.296552                    0.531965            0.372152  \n",
            "\n",
            "[5 rows x 40 columns]\n",
            "\n",
            "Normalized data statistics:\n",
            "       temperature_2m  relativehumidity_2m   dewpoint_2m  windspeed_10m  \\\n",
            "count    43752.000000         43752.000000  43752.000000   43752.000000   \n",
            "mean         0.573985             0.661788      0.596101       0.267087   \n",
            "std          0.179346             0.205438      0.201078       0.122642   \n",
            "min          0.000000             0.000000      0.000000       0.000000   \n",
            "25%          0.428571             0.512195      0.442184       0.179182   \n",
            "50%          0.569585             0.682927      0.591006       0.245353   \n",
            "75%          0.727189             0.829268      0.768737       0.342007   \n",
            "max          1.000000             1.000000      1.000000       1.000000   \n",
            "\n",
            "       windspeed_100m  winddirection_10m  winddirection_100m  windgusts_10m  \\\n",
            "count    43752.000000       43752.000000        43752.000000   43752.000000   \n",
            "mean         0.301033           0.564687            0.565046       0.253470   \n",
            "std          0.130681           0.268356            0.272063       0.124373   \n",
            "min          0.000000           0.000000            0.000000       0.000000   \n",
            "25%          0.208273           0.364903            0.361111       0.156794   \n",
            "50%          0.291484           0.623955            0.627778       0.233449   \n",
            "75%          0.383942           0.768802            0.772222       0.331010   \n",
            "max          1.000000           1.000000            1.000000       1.000000   \n",
            "\n",
            "              Power          hour  ...   Power_lag48  \\\n",
            "count  43752.000000  43752.000000  ...  43752.000000   \n",
            "mean       0.409157      0.500000  ...      0.409206   \n",
            "std        0.290916      0.300968  ...      0.290898   \n",
            "min        0.000000      0.000000  ...      0.000000   \n",
            "25%        0.150207      0.250000  ...      0.150308   \n",
            "50%        0.351004      0.500000  ...      0.351155   \n",
            "75%        0.665893      0.750000  ...      0.665893   \n",
            "max        1.000000      1.000000  ...      1.000000   \n",
            "\n",
            "       windspeed_100m_roll_mean_6  windspeed_100m_roll_std_6  \\\n",
            "count                43752.000000               43752.000000   \n",
            "mean                     0.299353                   0.137839   \n",
            "std                      0.132688                   0.082222   \n",
            "min                      0.000000                   0.000000   \n",
            "25%                      0.201986                   0.077984   \n",
            "50%                      0.286125                   0.120143   \n",
            "75%                      0.384222                   0.179094   \n",
            "max                      1.000000                   1.000000   \n",
            "\n",
            "       Power_roll_mean_6  windspeed_100m_roll_mean_12  \\\n",
            "count       43752.000000                 43752.000000   \n",
            "mean            0.409557                     0.333685   \n",
            "std             0.285429                     0.146205   \n",
            "min             0.000000                     0.000000   \n",
            "25%             0.156373                     0.224404   \n",
            "50%             0.353749                     0.316082   \n",
            "75%             0.658384                     0.428112   \n",
            "max             1.000000                     1.000000   \n",
            "\n",
            "       windspeed_100m_roll_std_12  Power_roll_mean_12  \\\n",
            "count                43752.000000        43752.000000   \n",
            "mean                     0.186948            0.410338   \n",
            "std                      0.102704            0.273217   \n",
            "min                      0.000000            0.000000   \n",
            "25%                      0.112780            0.171119   \n",
            "50%                      0.166899            0.361960   \n",
            "75%                      0.240974            0.640291   \n",
            "max                      1.000000            1.000000   \n",
            "\n",
            "       windspeed_100m_roll_mean_24  windspeed_100m_roll_std_24  \\\n",
            "count                 43752.000000                43752.000000   \n",
            "mean                      0.334524                    0.232816   \n",
            "std                       0.146483                    0.119355   \n",
            "min                       0.000000                    0.000000   \n",
            "25%                       0.223763                    0.147181   \n",
            "50%                       0.317196                    0.212067   \n",
            "75%                       0.430478                    0.294148   \n",
            "max                       1.000000                    1.000000   \n",
            "\n",
            "       Power_roll_mean_24  \n",
            "count        43752.000000  \n",
            "mean             0.416276  \n",
            "std              0.249642  \n",
            "min              0.000000  \n",
            "25%              0.204248  \n",
            "50%              0.387122  \n",
            "75%              0.610097  \n",
            "max              1.000000  \n",
            "\n",
            "[8 rows x 39 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7a405b39"
      },
      "source": [
        "### CELL 6: PREPARE FOR TIME SERIES"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3d264523",
        "outputId": "097af512-1731-4885-ded1-66f9b3bff85c"
      },
      "source": [
        "# Add group variable (all same location)\n",
        "data['group'] = '0' # Changed to string type\n",
        "data['idx'] = range(len(data))\n",
        "\n",
        "# Get all numeric columns except target and group\n",
        "feature_cols = data.select_dtypes(include=[np.number]).columns.tolist()\n",
        "feature_cols.remove('Power')\n",
        "feature_cols.remove('idx')\n",
        "\n",
        "print(f\"Feature columns ({len(feature_cols)}):\")\n",
        "print(feature_cols)\n",
        "\n",
        "max_encoder_length = 48  # 2 days\n",
        "max_prediction_length = 12  # Next 12 hours\n",
        "\n",
        "print(f\"\\nMax encoder length: {max_encoder_length} hours (2 days)\")\n",
        "print(f\"Max prediction length: {max_prediction_length} hours\")"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature columns (38):\n",
            "['temperature_2m', 'relativehumidity_2m', 'dewpoint_2m', 'windspeed_10m', 'windspeed_100m', 'winddirection_10m', 'winddirection_100m', 'windgusts_10m', 'hour', 'hour_sin', 'hour_cos', 'month', 'month_sin', 'month_cos', 'dayofweek', 'dayofweek_sin', 'dayofweek_cos', 'windspeed_100m_lag1', 'Power_lag1', 'windspeed_100m_lag2', 'Power_lag2', 'windspeed_100m_lag6', 'Power_lag6', 'windspeed_100m_lag12', 'Power_lag12', 'windspeed_100m_lag24', 'Power_lag24', 'windspeed_100m_lag48', 'Power_lag48', 'windspeed_100m_roll_mean_6', 'windspeed_100m_roll_std_6', 'Power_roll_mean_6', 'windspeed_100m_roll_mean_12', 'windspeed_100m_roll_std_12', 'Power_roll_mean_12', 'windspeed_100m_roll_mean_24', 'windspeed_100m_roll_std_24', 'Power_roll_mean_24']\n",
            "\n",
            "Max encoder length: 48 hours (2 days)\n",
            "Max prediction length: 12 hours\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_cutoff = len(data) - max_prediction_length - 100\n",
        "\n",
        "print(f\"Total data points: {len(data)}\")\n",
        "print(f\"Training cutoff: {training_cutoff}\")\n",
        "print(f\"Train size: {training_cutoff}\")\n",
        "print(f\"Test size: {len(data) - training_cutoff}\")\n",
        "\n",
        "training_dataset = TimeSeriesDataSet(\n",
        "    data[data.index < training_cutoff],\n",
        "    time_idx='idx',\n",
        "    target='Power',\n",
        "    group_ids=['group'],\n",
        "    max_encoder_length=max_encoder_length,\n",
        "    max_prediction_length=max_prediction_length,\n",
        "    static_categoricals=['group'],\n",
        "    time_varying_known_reals=feature_cols,\n",
        "    time_varying_unknown_reals=['Power'],\n",
        "    target_normalizer=GroupNormalizer(groups=['group']),\n",
        "    add_relative_time_idx=True,\n",
        "    add_target_scales=True,\n",
        ")\n",
        "\n",
        "print(\"\\nTimeSeriesDataSet created successfully!\")\n",
        "print(f\"Training dataset size: {len(training_dataset)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GFvgVlcOiHI5",
        "outputId": "bc8df223-eeda-479c-9d6d-dabe657fb510"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total data points: 43752\n",
            "Training cutoff: 43640\n",
            "Train size: 43640\n",
            "Test size: 112\n",
            "\n",
            "TimeSeriesDataSet created successfully!\n",
            "Training dataset size: 43581\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "511eeb20",
        "outputId": "69e23e5f-270e-4df4-f2bc-59b8f8a689b3"
      },
      "source": [
        "# Create validation dataset from the remainder of the data\n",
        "validation_dataset = TimeSeriesDataSet.from_dataset(training_dataset, data[data.index >= training_cutoff], predict=True)\n",
        "\n",
        "# Create dataloaders\n",
        "train_dataloader = training_dataset.to_dataloader(train=True, batch_size=32, num_workers=0)\n",
        "val_dataloader = validation_dataset.to_dataloader(train=False, batch_size=32, num_workers=0)\n",
        "\n",
        "print(\"Train and Validation dataloaders created!\")\n",
        "print(f\"Number of training batches: {len(train_dataloader)}\")\n",
        "print(f\"Number of validation batches: {len(val_dataloader)}\")\n",
        "\n",
        "# Check a batch from the training dataloader\n",
        "for x, y in train_dataloader:\n",
        "    print(f\"\\nTraining Batch shapes:\")\n",
        "    for key, value in x.items():\n",
        "        if isinstance(value, torch.Tensor):\n",
        "            print(f\"  X[{key}]: {value.shape}\")\n",
        "    print(f\"  Y[0]: {y[0].shape}\")\n",
        "    break\n",
        "\n",
        "# Check a batch from the validation dataloader\n",
        "for x, y in val_dataloader:\n",
        "    print(f\"\\nValidation Batch shapes:\")\n",
        "    for key, value in x.items():\n",
        "        if isinstance(value, torch.Tensor):\n",
        "            print(f\"  X[{key}]: {value.shape}\")\n",
        "    print(f\"  Y[0]: {y[0].shape}\")\n",
        "    break"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train and Validation dataloaders created!\n",
            "Number of training batches: 1361\n",
            "Number of validation batches: 1\n",
            "\n",
            "Training Batch shapes:\n",
            "  X[encoder_cat]: torch.Size([32, 48, 1])\n",
            "  X[encoder_cont]: torch.Size([32, 48, 42])\n",
            "  X[encoder_target]: torch.Size([32, 48])\n",
            "  X[encoder_lengths]: torch.Size([32])\n",
            "  X[decoder_cat]: torch.Size([32, 12, 1])\n",
            "  X[decoder_cont]: torch.Size([32, 12, 42])\n",
            "  X[decoder_target]: torch.Size([32, 12])\n",
            "  X[decoder_lengths]: torch.Size([32])\n",
            "  X[decoder_time_idx]: torch.Size([32, 12])\n",
            "  X[groups]: torch.Size([32, 1])\n",
            "  X[target_scale]: torch.Size([32, 2])\n",
            "  Y[0]: torch.Size([32, 12])\n",
            "\n",
            "Validation Batch shapes:\n",
            "  X[encoder_cat]: torch.Size([1, 48, 1])\n",
            "  X[encoder_cont]: torch.Size([1, 48, 42])\n",
            "  X[encoder_target]: torch.Size([1, 48])\n",
            "  X[encoder_lengths]: torch.Size([1])\n",
            "  X[decoder_cat]: torch.Size([1, 12, 1])\n",
            "  X[decoder_cont]: torch.Size([1, 12, 42])\n",
            "  X[decoder_target]: torch.Size([1, 12])\n",
            "  X[decoder_lengths]: torch.Size([1])\n",
            "  X[decoder_time_idx]: torch.Size([1, 12])\n",
            "  X[groups]: torch.Size([1, 1])\n",
            "  X[target_scale]: torch.Size([1, 2])\n",
            "  Y[0]: torch.Size([1, 12])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tft_model = TemporalFusionTransformer.from_dataset(\n",
        "    training_dataset,\n",
        "    learning_rate=0.001,\n",
        "    hidden_size=64,\n",
        "    attention_head_size=4,\n",
        "    dropout=0.2,\n",
        "    hidden_continuous_size=32,\n",
        "    output_size=7,\n",
        "    loss=QuantileLoss(),\n",
        "    log_interval=10,\n",
        ")\n",
        "\n",
        "print(\"Temporal Fusion Transformer model initialized!\")\n",
        "print(f\"Number of parameters: {sum(p.numel() for p in tft_model.parameters())}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sHKUt3HKiN1P",
        "outputId": "c6f331e1-254a-48f9-985e-86e99546660e"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Temporal Fusion Transformer model initialized!\n",
            "Number of parameters: 864715\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Starting training...\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Diagnostic check\n",
        "print(f\"Is tft_model an instance of pl.LightningModule? {isinstance(tft_model, pl.LightningModule)}\")\n",
        "\n",
        "trainer = pl.Trainer(\n",
        "    max_epochs=10,\n",
        "    accelerator='cpu',\n",
        "    enable_progress_bar=True,\n",
        "    logger=False,\n",
        "    callbacks=[\n",
        "        EarlyStopping(monitor='train_loss_epoch', patience=10, mode='min'),\n",
        "    ]\n",
        ")\n",
        "\n",
        "trainer.fit(tft_model, train_dataloader)\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"Training completed!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "id": "VubMHfF3iRdt",
        "outputId": "f5cd2ee2-6330-44f0-f587-d112b53a3c42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epoch 0/9  \u001b[38;2;98;6;224m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;98;6;224m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━\u001b[0m 714/1361 \u001b[2m0:10:06 • 0:08:57\u001b[0m \u001b[2;4m1.21it/s\u001b[0m \u001b[3mtrain_loss_step: 0.007\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Epoch 0/9  <span style=\"color: #6206e0; text-decoration-color: #6206e0\">━━━━━━━━━━━━━━━━━━━━╸</span><span style=\"color: #3a3a3a; text-decoration-color: #3a3a3a\">━━━━━━━━━━━━━━━━━━━</span> 714/1361 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">0:10:06 • 0:08:57</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; text-decoration: underline\">1.21it/s</span> <span style=\"font-style: italic\">train_loss_step: 0.007</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23279658"
      },
      "source": [
        "model_path = \"wind_power_tft_model.pkl\"\n",
        "\n",
        "checkpoint_data = {\n",
        "    'model': tft_model,\n",
        "    'scaler': scaler,\n",
        "    'training_dataset': training_dataset,\n",
        "    'max_encoder_length': max_encoder_length,\n",
        "    'max_prediction_length': max_prediction_length,\n",
        "    'feature_cols': feature_cols,\n",
        "    'numeric_cols': numeric_cols\n",
        "}\n",
        "\n",
        "with open(model_path, 'wb') as f:\n",
        "    pickle.dump(checkpoint_data, f)\n",
        "\n",
        "print(f\"Model saved to {model_path}\")\n",
        "print(f\"Model file size: {np.round(os.path.getsize(model_path)/1024/1024, 2)} MB\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get test data indices (last 100 hours)\n",
        "test_indices = list(range(training_cutoff, len(data)))[:100]\n",
        "\n",
        "# Create prediction dataset\n",
        "test_dataset = TimeSeriesDataSet(\n",
        "    data,\n",
        "    time_idx='idx',\n",
        "    target='Power',\n",
        "    group_ids=['group'],\n",
        "    max_encoder_length=max_encoder_length,\n",
        "    max_prediction_length=max_prediction_length,\n",
        "    static_categoricals=['group'],\n",
        "    time_varying_known_reals=feature_cols,\n",
        "    time_varying_unknown_reals=['Power'],\n",
        "    target_normalizer=training_dataset.target_normalizer,\n",
        "    add_relative_time_idx=True,\n",
        "    add_target_scales=True,\n",
        ")\n",
        "\n",
        "# Create prediction dataloader\n",
        "test_dataloader = test_dataset.to_dataloader(train=False, batch_size=1, num_workers=0)\n",
        "\n",
        "print(\"Making predictions on test set...\")\n",
        "raw_predictions = tft_model.predict(test_dataloader, return_x=True)\n",
        "\n",
        "predictions_tensor = raw_predictions[0]\n",
        "x_input = raw_predictions[1]\n",
        "\n",
        "print(f\"Predictions shape: {predictions_tensor.shape}\")"
      ],
      "metadata": {
        "id": "xgbtqZKh-D-d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to numpy\n",
        "predictions_np = predictions_tensor.cpu().numpy() if hasattr(predictions_tensor, 'cpu') else predictions_tensor\n",
        "if isinstance(predictions_np, tuple):\n",
        "    predictions_np = predictions_np[0]\n",
        "\n",
        "print(f\"Predictions numpy shape: {predictions_np.shape}\")\n",
        "\n",
        "# Get actual values from test set\n",
        "actual_test = data[training_cutoff:][f'Power'].values[:len(predictions_np)]\n",
        "\n",
        "print(f\"Actual test shape: {actual_test.shape}\")\n",
        "print(f\"Predictions shape: {predictions_np.shape}\")\n",
        "\n",
        "# Flatten if needed\n",
        "if predictions_np.ndim > 1:\n",
        "    predictions_np = predictions_np.reshape(-1)\n",
        "\n",
        "# Calculate metrics\n",
        "r2 = r2_score(actual_test, predictions_np)\n",
        "rmse = np.sqrt(mean_squared_error(actual_test, predictions_np))\n",
        "mape = mean_absolute_percentage_error(actual_test, predictions_np)\n",
        "mae = np.mean(np.abs(actual_test - predictions_np))\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"MODEL EVALUATION METRICS\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"R² Score:  {r2:.6f}\")\n",
        "print(f\"RMSE:      {rmse:.6f}\")\n",
        "print(f\"MAE:       {mae:.6f}\")\n",
        "print(f\"MAPE:      {mape:.6f}\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "if r2 >= 0.90:\n",
        "    print(\"✓ R² Score is above 0.90 - Excellent performance!\")\n",
        "elif r2 >= 0.80:\n",
        "    print(\"✓ R² Score is above 0.80 - Good performance!\")\n",
        "else:\n",
        "    print(\"⚠ R² Score below 0.80 - Consider tuning hyperparameters\")"
      ],
      "metadata": {
        "id": "Zm2c0UhL-X9V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot full test predictions\n",
        "plt.figure(figsize=(16, 6))\n",
        "plt.plot(actual_test[:200], label='Actual', marker='o', linewidth=2, markersize=4, alpha=0.7)\n",
        "plt.plot(predictions_np[:200], label='Predicted', marker='s', linewidth=2, markersize=4, alpha=0.7)\n",
        "plt.xlabel('Time Step', fontsize=12)\n",
        "plt.ylabel('Normalized Power', fontsize=12)\n",
        "plt.title(f'Wind Power Prediction - Test Set (R² = {r2:.4f})', fontsize=14, fontweight='bold')\n",
        "plt.legend(fontsize=11)\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.savefig('full_predictions.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"Full prediction plot saved!\")"
      ],
      "metadata": {
        "id": "rx2ualeB-dGW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract 12-hour ahead predictions\n",
        "prediction_length = 12\n",
        "num_samples = len(predictions_np) // prediction_length\n",
        "\n",
        "predictions_12h = predictions_np[:num_samples * prediction_length].reshape(-1, prediction_length)\n",
        "actual_12h = actual_test[:num_samples * prediction_length].reshape(-1, prediction_length)\n",
        "\n",
        "# Calculate metrics for each hour\n",
        "hourly_r2 = []\n",
        "hourly_rmse = []\n",
        "\n",
        "for hour in range(prediction_length):\n",
        "    h_r2 = r2_score(actual_12h[:, hour], predictions_12h[:, hour])\n",
        "    h_rmse = np.sqrt(mean_squared_error(actual_12h[:, hour], predictions_12h[:, hour]))\n",
        "    hourly_r2.append(h_r2)\n",
        "    hourly_rmse.append(h_rmse)\n",
        "\n",
        "print(\"\\nHourly Performance (12 hours ahead):\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"{'Hour':<8} {'R² Score':<15} {'RMSE':<15}\")\n",
        "print(\"=\" * 50)\n",
        "for hour in range(prediction_length):\n",
        "    print(f\"{hour+1:<8} {hourly_r2[hour]:<15.6f} {hourly_rmse[hour]:<15.6f}\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"Average: {np.mean(hourly_r2):<15.6f} {np.mean(hourly_rmse):<15.6f}\")"
      ],
      "metadata": {
        "id": "4vgxo7Sr-hD3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(2, 1, figsize=(14, 10))\n",
        "\n",
        "# Plot 1: R² Score per hour\n",
        "axes[0].bar(range(1, prediction_length + 1), hourly_r2, color='steelblue', alpha=0.7, edgecolor='black')\n",
        "axes[0].axhline(y=0.90, color='green', linestyle='--', linewidth=2, label='Target (0.90)')\n",
        "axes[0].set_xlabel('Hour Ahead', fontsize=12)\n",
        "axes[0].set_ylabel('R² Score', fontsize=12)\n",
        "axes[0].set_title('R² Score per Hour (12-Hour Ahead Prediction)', fontsize=13, fontweight='bold')\n",
        "axes[0].set_ylim([0, 1])\n",
        "axes[0].legend()\n",
        "axes[0].grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "# Plot 2: RMSE per hour\n",
        "axes[1].bar(range(1, prediction_length + 1), hourly_rmse, color='coral', alpha=0.7, edgecolor='black')\n",
        "axes[1].set_xlabel('Hour Ahead', fontsize=12)\n",
        "axes[1].set_ylabel('RMSE', fontsize=12)\n",
        "axes[1].set_title('RMSE per Hour (12-Hour Ahead Prediction)', fontsize=13, fontweight='bold')\n",
        "axes[1].grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('hourly_metrics.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"Hourly metrics plot saved!\")"
      ],
      "metadata": {
        "id": "Ikubrpl8-oPp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the last available data point for making a fresh prediction\n",
        "last_48_hours = data.iloc[-48:].copy()\n",
        "\n",
        "# Extract predictions for the last sample\n",
        "last_predictions = predictions_np[-prediction_length:]\n",
        "last_actual = actual_test[-prediction_length:]\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(12, 6))\n",
        "hours = np.arange(1, prediction_length + 1)\n",
        "plt.plot(hours, last_actual, 'o-', label='Actual Next 12 Hours', linewidth=2.5, markersize=8)\n",
        "plt.plot(hours, last_predictions, 's--', label='Predicted Next 12 Hours', linewidth=2.5, markersize=8)\n",
        "plt.fill_between(hours, last_actual, last_predictions, alpha=0.2)\n",
        "plt.xlabel('Hour Ahead', fontsize=12)\n",
        "plt.ylabel('Normalized Power', fontsize=12)\n",
        "plt.title('Example: Next 12 Hours Wind Power Prediction', fontsize=14, fontweight='bold')\n",
        "plt.legend(fontsize=11)\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.xticks(hours)\n",
        "plt.tight_layout()\n",
        "plt.savefig('next_12_hours_prediction.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "# Print detailed table\n",
        "print(\"\\nDetailed 12-Hour Prediction:\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"{'Hour':<8} {'Actual Power':<20} {'Predicted Power':<20} {'Error':<15}\")\n",
        "print(\"=\" * 70)\n",
        "for h in range(prediction_length):\n",
        "    error = last_actual[h] - last_predictions[h]\n",
        "    print(f\"{h+1:<8} {last_actual[h]:<20.6f} {last_predictions[h]:<20.6f} {error:<15.6f}\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "print(\"\\n✓ Training and prediction completed successfully!\")\n",
        "print(f\"✓ Model saved to: {model_path}\")"
      ],
      "metadata": {
        "id": "0YbT6u49-pPu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e65fcc74"
      },
      "source": [
        "# Task\n",
        "The user has approved the previous response. To proceed with the plan, the next step is to adapt the training code for the cloud. This involves converting the existing model training logic from the notebook into a standalone Python script, designed to handle data loading and trained model saving.\n",
        "\n",
        "I will now create a new file named `train.py` and populate it with the necessary code from the notebook to perform the training. This script will be structured to be runnable as a standalone application. I will focus on extracting the relevant logic for data preprocessing, model definition, training, and saving the trained model.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5553d69"
      },
      "source": [
        "## Adapt Training Code for Cloud\n",
        "\n",
        "### Subtask:\n",
        "Convert the existing model training logic from the notebook into a standalone Python script (`train.py`), designed to handle data loading, preprocessing, model definition, training, and trained model saving.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fd5d4eb6"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask is to create a standalone Python script `train.py` by consolidating code from various notebook cells. This command will generate the content of `train.py` and save it to a file, fulfilling all the instructions from step 2 to 14.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e0ce91fc"
      },
      "source": [
        "script_content = '''\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "import warnings\n",
        "import kagglehub\n",
        "from datetime import timedelta\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_absolute_percentage_error, r2_score, mean_squared_error\n",
        "import lightning.pytorch as pl\n",
        "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from pytorch_lightning.loggers import CSVLogger\n",
        "from pytorch_forecasting import TimeSeriesDataSet, TemporalFusionTransformer\n",
        "from pytorch_forecasting.data import GroupNormalizer\n",
        "from pytorch_forecasting.metrics import QuantileLoss, MAE, RMSE\n",
        "import torch\n",
        "import os\n",
        "\n",
        "def main():\n",
        "    warnings.filterwarnings('ignore')\n",
        "    pl.seed_everything(42)\n",
        "    print(\"INFO: Seed set to 42\")\n",
        "\n",
        "    # Data loading and initial preprocessing\n",
        "    path = kagglehub.dataset_download(\"mubashirrahim/wind-power-generation-data-forecasting\")\n",
        "    data = pd.read_csv(path + \"/Location1.csv\")\n",
        "\n",
        "    data['Time'] = pd.to_datetime(data['Time'])\n",
        "    data = data.sort_values('Time').reset_index(drop=True)\n",
        "    data = data.ffill().bfill()\n",
        "\n",
        "    print(\"Data Shape:\", data.shape)\n",
        "    print(\"\\nFirst few rows:\")\n",
        "    print(data.head())\n",
        "\n",
        "    # Cyclic feature engineering\n",
        "    data['hour'] = data['Time'].dt.hour\n",
        "    data['hour_sin'] = np.sin(2 * np.pi * data['hour'] / 24)\n",
        "    data['hour_cos'] = np.cos(2 * np.pi * data['hour'] / 24)\n",
        "\n",
        "    data['month'] = data['Time'].dt.month\n",
        "    data['month_sin'] = np.sin(2 * np.pi * data['month'] / 12)\n",
        "    data['month_cos'] = np.cos(2 * np.pi * data['month'] / 12)\n",
        "\n",
        "    data['dayofweek'] = data['Time'].dt.dayofweek\n",
        "    data['dayofweek_sin'] = np.sin(2 * np.pi * data['dayofweek'] / 7)\n",
        "    data['dayofweek_cos'] = np.cos(2 * np.pi * data['dayofweek'] / 7)\n",
        "    print(\"Cyclic features added!\")\n",
        "\n",
        "    # Lag feature generation\n",
        "    lags = [1, 2, 6, 12, 24, 48]\n",
        "    for lag in lags:\n",
        "        data[f'windspeed_100m_lag{lag}'] = data['windspeed_100m'].shift(lag)\n",
        "        data[f'Power_lag{lag}'] = data['Power'].shift(lag)\n",
        "    print(\"Lag features added!\")\n",
        "\n",
        "    # Rolling feature creation and dropna\n",
        "    windows = [6, 12, 24]\n",
        "    for window in windows:\n",
        "        data[f'windspeed_100m_roll_mean_{window}'] = data['windspeed_100m'].rolling(window).mean()\n",
        "        data[f'windspeed_100m_roll_std_{window}'] = data['windspeed_100m'].rolling(window).std()\n",
        "        data[f'Power_roll_mean_{window}'] = data['Power'].rolling(window).mean()\n",
        "    print(\"Rolling features added!\")\n",
        "    data = data.dropna().reset_index(drop=True)\n",
        "    print(f\"\\nFinal data shape after dropping NaNs: {data.shape}\")\n",
        "\n",
        "    # Data normalization\n",
        "    numeric_cols = data.select_dtypes(include=[np.number]).columns.tolist()\n",
        "    scaler = MinMaxScaler()\n",
        "    data[numeric_cols] = scaler.fit_transform(data[numeric_cols])\n",
        "    print(\"Data normalized!\")\n",
        "\n",
        "    # TimeSeriesDataSet preparation\n",
        "    data['group'] = '0'\n",
        "    data['idx'] = range(len(data))\n",
        "\n",
        "    feature_cols = data.select_dtypes(include=[np.number]).columns.tolist()\n",
        "    feature_cols.remove('Power')\n",
        "    feature_cols.remove('idx')\n",
        "\n",
        "    max_encoder_length = 48\n",
        "    max_prediction_length = 12\n",
        "\n",
        "    print(f\"Max encoder length: {max_encoder_length} hours (2 days)\")\n",
        "    print(f\"Max prediction length: {max_prediction_length} hours\")\n",
        "\n",
        "    training_cutoff = len(data) - max_prediction_length - 100\n",
        "\n",
        "    # TimeSeriesDataSet and DataLoader creation\n",
        "    training_dataset = TimeSeriesDataSet(\n",
        "        data[data.index < training_cutoff],\n",
        "        time_idx='idx',\n",
        "        target='Power',\n",
        "        group_ids=['group'],\n",
        "        max_encoder_length=max_encoder_length,\n",
        "        max_prediction_length=max_prediction_length,\n",
        "        static_categoricals=['group'],\n",
        "        time_varying_known_reals=feature_cols,\n",
        "        time_varying_unknown_reals=['Power'],\n",
        "        target_normalizer=GroupNormalizer(groups=['group']),\n",
        "        add_relative_time_idx=True,\n",
        "        add_target_scales=True,\n",
        "    )\n",
        "\n",
        "    validation_dataset = TimeSeriesDataSet.from_dataset(training_dataset, data[data.index >= training_cutoff], predict=True)\n",
        "\n",
        "    train_dataloader = training_dataset.to_dataloader(train=True, batch_size=32, num_workers=0)\n",
        "    val_dataloader = validation_dataset.to_dataloader(train=False, batch_size=32, num_workers=0)\n",
        "    print(\"Train and Validation dataloaders created!\")\n",
        "\n",
        "    # TemporalFusionTransformer initialization\n",
        "    tft_model = TemporalFusionTransformer.from_dataset(\n",
        "        training_dataset,\n",
        "        learning_rate=0.001,\n",
        "        hidden_size=64,\n",
        "        attention_head_size=4,\n",
        "        dropout=0.2,\n",
        "        hidden_continuous_size=32,\n",
        "        output_size=7,\n",
        "        loss=QuantileLoss(),\n",
        "        log_interval=10,\n",
        "    )\n",
        "    print(\"Temporal Fusion Transformer model initialized!\")\n",
        "\n",
        "    # Trainer setup and training\n",
        "    print(\"Starting training...\")\n",
        "    trainer = pl.Trainer(\n",
        "        max_epochs=20,\n",
        "        accelerator='cpu',\n",
        "        enable_progress_bar=True,\n",
        "        logger=False,\n",
        "        callbacks=[\n",
        "            EarlyStopping(monitor='train_loss_epoch', patience=10, mode='min'),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    trainer.fit(tft_model, train_dataloader)\n",
        "    print(\"Training completed!\")\n",
        "\n",
        "    # Model saving\n",
        "    model_path = \"wind_power_tft_model.pkl\"\n",
        "    checkpoint_data = {\n",
        "        'model': tft_model,\n",
        "        'scaler': scaler,\n",
        "        'training_dataset': training_dataset,\n",
        "        'max_encoder_length': max_encoder_length,\n",
        "        'max_prediction_length': max_prediction_length,\n",
        "        'feature_cols': feature_cols,\n",
        "        'numeric_cols': numeric_cols\n",
        "    }\n",
        "\n",
        "    with open(model_path, 'wb') as f:\n",
        "        pickle.dump(checkpoint_data, f)\n",
        "    print(f\"Model saved to {model_path}\")\n",
        "    print(f\"Model file size: {np.round(os.path.getsize(model_path)/1024/1024, 2)} MB\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n",
        "'''\n",
        "\n",
        "with open('train.py', 'w') as f:\n",
        "    f.write(script_content)\n",
        "\n",
        "print(\"train.py script created successfully!\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}