{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b68fd6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\anaconda3\\envs\\tft\\lib\\site-packages\\pytorch_forecasting\\models\\base\\_base_model.py:28: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "import io\n",
    "import dash\n",
    "from dash import dcc, html, Input, Output, State, callback\n",
    "import dash_bootstrap_components as dbc\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import warnings\n",
    "import torch\n",
    "from datetime import timedelta\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, mean_absolute_percentage_error\n",
    "from pytorch_forecasting import TemporalFusionTransformer\n",
    "\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "329955bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from tft_model.ckpt...\n",
      "Model loaded.\n"
     ]
    }
   ],
   "source": [
    "# ==================== CONFIGURATION ====================\n",
    "MODEL_CHECKPOINT = \"tft_model.ckpt\"\n",
    "METADATA_FILE = \"tft_metadata.pkl\"\n",
    "DEFAULT_FORECAST_HORIZON = 12\n",
    "CONTEXT_WINDOW = 24\n",
    "\n",
    "# Load Model\n",
    "loaded_model = None\n",
    "model_status_msg = \"Checking model...\"\n",
    "model_status_color = \"warning\"\n",
    "\n",
    "try:\n",
    "    print(f\"Loading model from {MODEL_CHECKPOINT}...\")\n",
    "    loaded_model = TemporalFusionTransformer.load_from_checkpoint(MODEL_CHECKPOINT)\n",
    "    loaded_model.eval()\n",
    "    model_status_msg = \"‚úÖ Model Loaded Successfully\"\n",
    "    model_status_color = \"success\"\n",
    "    print(\"Model loaded.\")\n",
    "except Exception as e:\n",
    "    model_status_msg = f\"‚ùå Model Load Failed: {str(e)}\"\n",
    "    model_status_color = \"danger\"\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01578547",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_features(df, fill_na=True):\n",
    "    \"\"\"Robust feature engineering with safe datetime handling\"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    # ===============================\n",
    "    # 1. Parse TIMESTAMP SAFELY\n",
    "    # ===============================\n",
    "    if \"TIMESTAMP\" not in df.columns:\n",
    "        raise ValueError(\"CSV must contain a 'TIMESTAMP' column\")\n",
    "\n",
    "    df[\"TIMESTAMP\"] = pd.to_datetime(\n",
    "        df[\"TIMESTAMP\"],\n",
    "        infer_datetime_format=True,\n",
    "        errors=\"coerce\"\n",
    "    )\n",
    "\n",
    "    # Drop invalid timestamps\n",
    "    df = df.dropna(subset=[\"TIMESTAMP\"])\n",
    "\n",
    "    if df.empty:\n",
    "        raise ValueError(\"All TIMESTAMP values are invalid after parsing\")\n",
    "\n",
    "    # ===============================\n",
    "    # 2. Sort + Set Index\n",
    "    # ===============================\n",
    "    df = df.sort_values(\"TIMESTAMP\")\n",
    "    df = df.set_index(\"TIMESTAMP\")\n",
    "\n",
    "    # ===============================\n",
    "    # 3. Resample SAFELY\n",
    "    # ===============================\n",
    "    if not isinstance(df.index, pd.DatetimeIndex):\n",
    "        raise TypeError(\"Index must be DatetimeIndex for resampling\")\n",
    "\n",
    "    df = df.resample(\"1H\").asfreq()\n",
    "\n",
    "    # ===============================\n",
    "    # 4. Handle Missing Values\n",
    "    # ===============================\n",
    "    numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "    df[numeric_cols] = df[numeric_cols].interpolate(limit_direction=\"both\")\n",
    "\n",
    "    df = df.reset_index()\n",
    "\n",
    "    # ===============================\n",
    "    # 5. Time Index for TFT\n",
    "    # ===============================\n",
    "    start_time = df[\"TIMESTAMP\"].min()\n",
    "    df[\"idx\"] = ((df[\"TIMESTAMP\"] - start_time).dt.total_seconds() // 3600).astype(int)\n",
    "\n",
    "    # ===============================\n",
    "    # 6. Group ID (Required by TFT)\n",
    "    # ===============================\n",
    "    if \"group\" not in df.columns:\n",
    "        df[\"group\"] = \"0\"\n",
    "\n",
    "    # ===============================\n",
    "    # 7. Cyclical Time Features\n",
    "    # ===============================\n",
    "    df[\"hour\"] = df[\"TIMESTAMP\"].dt.hour\n",
    "    df[\"hour_sin\"] = np.sin(2 * np.pi * df[\"hour\"] / 24)\n",
    "    df[\"hour_cos\"] = np.cos(2 * np.pi * df[\"hour\"] / 24)\n",
    "\n",
    "    df[\"dayofweek\"] = df[\"TIMESTAMP\"].dt.dayofweek\n",
    "    df[\"dayofweek_sin\"] = np.sin(2 * np.pi * df[\"dayofweek\"] / 7)\n",
    "    df[\"dayofweek_cos\"] = np.cos(2 * np.pi * df[\"dayofweek\"] / 7)\n",
    "\n",
    "    df[\"month\"] = df[\"TIMESTAMP\"].dt.month\n",
    "    df[\"month_sin\"] = np.sin(2 * np.pi * df[\"month\"] / 12)\n",
    "    df[\"month_cos\"] = np.cos(2 * np.pi * df[\"month\"] / 12)\n",
    "\n",
    "    # ===============================\n",
    "    # 8. Lag Features\n",
    "    # ===============================\n",
    "    lags = [1, 2, 6, 12, 24]\n",
    "    for lag in lags:\n",
    "        df[f\"TARGETVAR_lag{lag}\"] = df[\"TARGETVAR\"].shift(lag)\n",
    "\n",
    "    # ===============================\n",
    "    # 9. Rolling Statistics\n",
    "    # ===============================\n",
    "    for w in [6, 12, 24]:\n",
    "        df[f\"U10_roll_mean_{w}\"] = df[\"U10\"].rolling(w).mean()\n",
    "        df[f\"U10_roll_std_{w}\"] = df[\"U10\"].rolling(w).std()\n",
    "        df[f\"TARGETVAR_roll_mean_{w}\"] = df[\"TARGETVAR\"].rolling(w).mean()\n",
    "\n",
    "    # ===============================\n",
    "    # 10. Final NA Cleanup\n",
    "    # ===============================\n",
    "    if fill_na:\n",
    "        num_cols = df.select_dtypes(include=[np.number]).columns\n",
    "        df[num_cols] = df[num_cols].fillna(method=\"ffill\").fillna(method=\"bfill\")\n",
    "        df = df.fillna(0)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c05e8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_prediction_with_interpretation(df, model):\n",
    "    \"\"\"Run model.predict and extract quantiles AND interpretation\"\"\"\n",
    "    try:\n",
    "        # 1. Predict\n",
    "        raw_prediction = model.predict(df, mode=\"raw\", return_x=True)\n",
    "        preds = raw_prediction.output[\"prediction\"] # (Batch, Time, Quantiles)\n",
    "        \n",
    "        # 2. Interpret (Feature Importance & Attention)\n",
    "        # === FIX: Use reduction=\"none\" to preserve batch dimension ===\n",
    "        interpretation = model.interpret_output(raw_prediction.output, reduction=\"none\")\n",
    "        \n",
    "        # Take the last prediction step (latest forecast)\n",
    "        latest_pred = preds[-1] \n",
    "        \n",
    "        # Extract quantiles\n",
    "        n_q = latest_pred.shape[-1]\n",
    "        res = {'quantiles': {}}\n",
    "        \n",
    "        if n_q >= 7:\n",
    "            res['quantiles']['p50'] = latest_pred[:, 3].cpu().numpy()\n",
    "            res['quantiles']['p10'] = latest_pred[:, 1].cpu().numpy()\n",
    "            res['quantiles']['p90'] = latest_pred[:, 5].cpu().numpy()\n",
    "            res['quantiles']['p02'] = latest_pred[:, 0].cpu().numpy()\n",
    "            res['quantiles']['p98'] = latest_pred[:, 6].cpu().numpy()\n",
    "        else:\n",
    "            res['quantiles']['p50'] = latest_pred[:, 0].cpu().numpy()\n",
    "            res['quantiles']['p10'] = res['quantiles']['p50']\n",
    "            res['quantiles']['p90'] = res['quantiles']['p50']\n",
    "            res['quantiles']['p02'] = res['quantiles']['p50']\n",
    "            res['quantiles']['p98'] = res['quantiles']['p50']\n",
    "        \n",
    "        # Store Interpretation Data\n",
    "        feat_importance = {}\n",
    "        for key in ['encoder_variables', 'decoder_variables', 'static_variables']:\n",
    "            if key in interpretation:\n",
    "                # With reduction=\"none\", shape is (Batch, Features)\n",
    "                # We select [-1] for the last sample\n",
    "                weights = interpretation[key][-1].cpu().numpy()\n",
    "                \n",
    "                # Normalize\n",
    "                total = weights.sum() + 1e-9\n",
    "                feat_importance[key] = (weights / total) * 100\n",
    "                \n",
    "        res['importance'] = feat_importance\n",
    "        \n",
    "        # Attention\n",
    "        if 'attention' in interpretation:\n",
    "            # Shape: (Batch, Prediction_Length, Encoder_Length)\n",
    "            # We take the last sample -> (Prediction_Length, Encoder_Length)\n",
    "            attn = interpretation['attention'][-1].cpu().numpy()\n",
    "            \n",
    "            # Check dimensions before averaging\n",
    "            if attn.ndim == 2:\n",
    "                # Average over the horizon to see \"general importance of past steps\"\n",
    "                avg_attn = attn.mean(axis=0) \n",
    "                res['attention'] = avg_attn\n",
    "            elif attn.ndim == 1:\n",
    "                # Fallback if attention is already collapsed\n",
    "                res['attention'] = attn\n",
    "            else:\n",
    "                res['attention'] = None\n",
    "            \n",
    "        return res, raw_prediction.x\n",
    "\n",
    "    except Exception as e:\n",
    "        # Graceful fallback if interpretation fails\n",
    "        print(f\"Interpretation Error: {e}\")\n",
    "        # Re-raise or return minimal results\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223879e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== DASH APP ====================\n",
    "app = dash.Dash(__name__, external_stylesheets=[dbc.themes.BOOTSTRAP])\n",
    "\n",
    "app.layout = dbc.Container([\n",
    "    dbc.Row([dbc.Col([\n",
    "        html.H2(\"‚ö° TFT Wind Power Dashboard\", className=\"text-center mt-4\"),\n",
    "        html.P(\"Forecast | Evaluation | Feature Attribution\", className=\"text-center text-muted mb-4\")\n",
    "    ])]),\n",
    "    \n",
    "    # Upload & Controls\n",
    "    dbc.Row([\n",
    "        dbc.Col([\n",
    "            dbc.Card([dbc.CardBody([\n",
    "                html.H6(\"1. Upload Data (CSV)\", className=\"card-subtitle text-muted mb-2\"),\n",
    "                dcc.Upload(\n",
    "                    id='upload-data',\n",
    "                    children=html.Div(['üìÇ Drag & Drop or Click to Upload']),\n",
    "                    style={'border': '2px dashed #007bff', 'borderRadius': '10px', 'textAlign': 'center', 'padding': '15px', 'cursor': 'pointer', 'backgroundColor': '#f8f9fa'},\n",
    "                    multiple=False\n",
    "                ),\n",
    "                html.Div(id='file-name-display', className=\"mt-2 text-primary small fw-bold\")\n",
    "            ])], className=\"h-100\")\n",
    "        ], md=8),\n",
    "        \n",
    "        dbc.Col([\n",
    "            dbc.Card([dbc.CardBody([\n",
    "                html.H6(\"2. System Status\", className=\"card-subtitle text-muted mb-2\"),\n",
    "                dbc.Badge(model_status_msg, color=model_status_color, className=\"mb-2 p-2 w-100\"),\n",
    "                dbc.Button(\"üöÄ Run Analysis\", id='predict-btn', color=\"primary\", className=\"w-100\", disabled=(loaded_model is None))\n",
    "            ])], className=\"h-100\")\n",
    "        ], md=4)\n",
    "    ], className=\"mb-4\"),\n",
    "    \n",
    "    # Main Content Tabs\n",
    "    dbc.Tabs([\n",
    "        dbc.Tab(label=\"üìà Forecast & Backtest\", tab_id=\"tab-forecast\"),\n",
    "        dbc.Tab(label=\"üß† Model Insights (XAI)\", tab_id=\"tab-insights\"),\n",
    "        dbc.Tab(label=\"üìä Evaluation Metrics\", tab_id=\"tab-metrics\"),\n",
    "    ], id=\"tabs\", active_tab=\"tab-forecast\", className=\"mb-3\"),\n",
    "    \n",
    "    html.Div(id='tab-content')\n",
    "    \n",
    "], fluid=True, style={'backgroundColor': '#f4f6f9', 'minHeight': '100vh', 'padding': '20px'})\n",
    "\n",
    "# --- Callbacks ---\n",
    "@callback(Output('file-name-display', 'children'), Input('upload-data', 'filename'))\n",
    "def display_name(name): return f\"üìÑ {name}\" if name else \"\"\n",
    "\n",
    "@callback(\n",
    "    Output('tab-content', 'children'),\n",
    "    [Input('predict-btn', 'n_clicks'), Input('tabs', 'active_tab')],\n",
    "    [State('upload-data', 'contents'), State('upload-data', 'filename')],\n",
    "    prevent_initial_call=False\n",
    ")\n",
    "def render_content(n_clicks, active_tab, contents, filename):\n",
    "    # Initial Load\n",
    "    if not n_clicks and not contents:\n",
    "        return dbc.Alert(\"Please upload a file and click 'Run Analysis' to begin.\", color=\"info\")\n",
    "    \n",
    "    if not contents:\n",
    "        return dbc.Alert(\"‚ö†Ô∏è No file uploaded.\", color=\"warning\")\n",
    "\n",
    "    try:\n",
    "        # Process Data\n",
    "        content_type, content_string = contents.split(',')\n",
    "        decoded = base64.b64decode(content_string)\n",
    "        df = pd.read_csv(io.StringIO(decoded.decode('utf-8')))\n",
    "        \n",
    "        if len(df) < (CONTEXT_WINDOW + DEFAULT_FORECAST_HORIZON):\n",
    "             return dbc.Alert(\"‚ùå Not enough data. Need at least 48 hours.\", color=\"danger\")\n",
    "        \n",
    "        df_proc = add_features(df, fill_na=True)\n",
    "    \n",
    "        # === 1. Run Calculations (Validation & Future) ===\n",
    "        \n",
    "        # A. Validation (Backtest Last 12h)\n",
    "        val_res, val_x = run_prediction_with_interpretation(df_proc, loaded_model)\n",
    "        val_preds = val_res['quantiles']\n",
    "        \n",
    "        val_time = df_proc['TIMESTAMP'].iloc[-DEFAULT_FORECAST_HORIZON:]\n",
    "        val_actual = df_proc['Power'].iloc[-DEFAULT_FORECAST_HORIZON:].values\n",
    "        \n",
    "        # Metrics Calculation\n",
    "        mae = mean_absolute_error(val_actual, val_preds['p50'])\n",
    "        rmse = np.sqrt(mean_squared_error(val_actual, val_preds['p50']))\n",
    "        mape = mean_absolute_percentage_error(val_actual, val_preds['p50'])\n",
    "        r2 = r2_score(val_actual, val_preds['p50'])\n",
    "\n",
    "        # B. Future Forecast\n",
    "        last_time = df_proc['TIMESTAMP'].iloc[-1]\n",
    "        future_times = [last_time + timedelta(hours=x) for x in range(1, 13)]\n",
    "        future_df = pd.DataFrame({'TIMESTAMP'TAMP': future_times})\n",
    "        df_extended = pd.concat([df_proc, future_df], ignore_index=True).ffill()\n",
    "        df_extended.loc[df_extended.index[-12:], 'Power'] = np.nan\n",
    "        df_fut_proc = add_features(df_extended, fill_na=True)\n",
    "        \n",
    "        fut_res, _ = run_prediction_with_interpretation(df_fut_proc, loaded_model)\n",
    "        fut_preds = fut_res['quantiles']\n",
    "\n",
    "        # === 2. Render Based on Tab ===\n",
    "        \n",
    "        if active_tab == \"tab-forecast\":\n",
    "            # --- Forecast Plots ---\n",
    "            # Validation Plot\n",
    "            fig_val = go.Figure()\n",
    "            fig_val.add_trace(go.Scatter(x=list(val_time)+list(val_time)[::-1], y=list(val_preds['p90'])+list(val_preds['p10'])[::-1], fill='toself', fillcolor='rgba(255,0,0,0.1)', line=dict(width=0), name='90% Conf'))\n",
    "            fig_val.add_trace(go.Scatter(x=val_time, y=val_preds['p50'], name='Predicted', line=dict(color='red')))\n",
    "            fig_val.add_trace(go.Scatter(x=val_time, y=val_actual, name='Actual', mode='markers+lines', line=dict(color='blue')))\n",
    "            fig_val.update_layout(title=\"Backtest: Model vs Actual (Last 12h)\", template=\"plotly_white\", margin=dict(l=20, r=20, t=40, b=20))\n",
    "            \n",
    "            # Future Plot\n",
    "            fig_fut = go.Figure()\n",
    "            fig_fut.add_trace(go.Scatter(x=list(future_times)+list(future_times)[::-1], y=list(fut_preds['p98'])+list(fut_preds['p02'])[::-1], fill='toself', fillcolor='rgba(0,0,255,0.1)', line=dict(width=0), name='98% Conf'))\n",
    "            fig_fut.add_trace(go.Scatter(x=list(future_times)+list(future_times)[::-1], y=list(fut_preds['p90'])+list(fut_preds['p10'])[::-1], fill='toself', fillcolor='rgba(0,0,255,0.2)', line=dict(width=0), name='90% Conf'))\n",
    "            fig_fut.add_trace(go.Scatter(x=future_times, y=fut_preds['p50'], name='Future Forecast', line=dict(color='blue', width=3)))\n",
    "            fig_fut.update_layout(title=\"Future Forecast (Next 12h)\", template=\"plotly_white\", margin=dict(l=20, r=20, t=40, b=20))\n",
    "            \n",
    "            return html.Div([\n",
    "                dbc.Row([dbc.Col(dcc.Graph(figure=fig_val), lg=6), dbc.Col(dcc.Graph(figure=fig_fut), lg=6)])\n",
    "            ])\n",
    "\n",
    "        elif active_tab == \"tab-insights\":\n",
    "            # --- Feature Importance & Attention ---\n",
    "            # 1. Feature Importance Plot\n",
    "            importance_data = []\n",
    "            if 'encoder_variables' in fut_res['importance']:\n",
    "                # Try to use model names if available, else indices\n",
    "                try:\n",
    "                    enc_names = loaded_model.encoder_variables\n",
    "                except:\n",
    "                    enc_names = [f\"Enc_{i}\" for i in range(len(fut_res['importance']['encoder_variables']))]\n",
    "                    \n",
    "                vals = fut_res['importance']['encoder_variables']\n",
    "                if len(enc_names) == len(vals):\n",
    "                    for n, v in zip(enc_names, vals): importance_data.append({'Feature': n, 'Importance': v, 'Type': 'Encoder'})\n",
    "            \n",
    "            if 'decoder_variables' in fut_res['importance']:\n",
    "                try:\n",
    "                    dec_names = loaded_model.decoder_variables\n",
    "                except:\n",
    "                    dec_names = [f\"Dec_{i}\" for i in range(len(fut_res['importance']['decoder_variables']))]\n",
    "\n",
    "                vals = fut_res['importance']['decoder_variables']\n",
    "                if len(dec_names) == len(vals):\n",
    "                    for n, v in zip(dec_names, vals): importance_data.append({'Feature': n, 'Importance': v, 'Type': 'Decoder'})\n",
    "            \n",
    "            if importance_data:\n",
    "                df_imp = pd.DataFrame(importance_data).sort_values('Importance', ascending=True)\n",
    "                fig_imp = px.bar(df_imp, x='Importance', y='Feature', color='Type', orientation='h', title=\"Feature Importance (Variable Selection Network)\")\n",
    "                fig_imp.update_layout(template=\"plotly_white\")\n",
    "            else:\n",
    "                fig_imp = go.Figure().add_annotation(text=\"No feature importance available\", showarrow=False)\n",
    "            \n",
    "            # 2. Attention Plot\n",
    "            if 'attention' in fut_res and fut_res['attention'] is not None:\n",
    "                attn_weights = fut_res['attention']\n",
    "                lookback_len = len(attn_weights)\n",
    "                x_axis = np.arange(-lookback_len, 0)\n",
    "                \n",
    "                fig_attn = go.Figure()\n",
    "                fig_attn.add_trace(go.Scatter(x=x_axis, y=attn_weights, fill='tozeroy', mode='lines', line=dict(color='purple')))\n",
    "                fig_attn.update_layout(\n",
    "                    title=\"Temporal Attention: Which past hours mattered most?\",\n",
    "                    xaxis_title=\"Time relative to Forecast Start (Hours)\",\n",
    "                    yaxis_title=\"Attention Weight\",\n",
    "                    template=\"plotly_white\"\n",
    "                )\n",
    "            else:\n",
    "                fig_attn = go.Figure().add_annotation(text=\"Attention weights not available\", showarrow=False)\n",
    "            \n",
    "            return html.Div([\n",
    "                dbc.Row([dbc.Col(dcc.Graph(figure=fig_imp), lg=6), dbc.Col(dcc.Graph(figure=fig_attn), lg=6)]),\n",
    "                dbc.Alert(\"üí° 'Attention' shows which historical time steps the model focused on to make the current prediction.\", color=\"light\", className=\"mt-2\")\n",
    "            ])\n",
    "\n",
    "        elif active_tab == \"tab-metrics\":\n",
    "            # --- Metrics Table & Residuals ---\n",
    "            cards = dbc.Row([\n",
    "                dbc.Col(dbc.Card([dbc.CardBody([html.H4(f\"{mae:.4f}\", className=\"text-primary\"), html.P(\"MAE (Mean Abs Error)\", className=\"small text-muted\")])], className=\"text-center shadow-sm\"), width=3),\n",
    "                dbc.Col(dbc.Card([dbc.CardBody([html.H4(f\"{rmse:.4f}\", className=\"text-danger\"), html.P(\"RMSE (Root Mean Sq Error)\", className=\"small text-muted\")])], className=\"text-center shadow-sm\"), width=3),\n",
    "                dbc.Col(dbc.Card([dbc.CardBody([html.H4(f\"{mape:.2%}\", className=\"text-warning\"), html.P(\"MAPE (Mean Abs % Error)\", className=\"small text-muted\")])], className=\"text-center shadow-sm\"), width=3),\n",
    "                dbc.Col(dbc.Card([dbc.CardBody([html.H4(f\"{r2:.4f}\", className=\"text-success\"), html.P(\"R¬≤ Score\", className=\"small text-muted\")])], className=\"text-center shadow-sm\"), width=3),\n",
    "            ], className=\"mb-4\")\n",
    "            \n",
    "            residuals = val_actual - val_preds['p50']\n",
    "            fig_res = go.Figure()\n",
    "            fig_res.add_trace(go.Bar(x=val_time, y=residuals, name='Residuals', marker_color='gray'))\n",
    "            fig_res.add_hline(y=0, line_dash=\"dash\", line_color=\"black\")\n",
    "            fig_res.update_layout(title=\"Prediction Residuals (Actual - Predicted)\", xaxis_title=\"Time\", yaxis_title=\"Error (MW)\", template=\"plotly_white\")\n",
    "            \n",
    "            fig_scat = px.scatter(x=val_actual, y=val_preds['p50'], labels={'x': 'Actual Power', 'y': 'Predicted Power'}, title=\"Actual vs Predicted Scatter\")\n",
    "            fig_scat.add_shape(type=\"line\", x0=val_actual.min(), y0=val_actual.min(), x1=val_actual.max(), y1=val_actual.max(), line=dict(color=\"Red\", dash=\"dash\"))\n",
    "            fig_scat.update_layout(template=\"plotly_white\")\n",
    "\n",
    "            return html.Div([\n",
    "                cards,\n",
    "                dbc.Row([dbc.Col(dcc.Graph(figure=fig_res), lg=8), dbc.Col(dcc.Graph(figure=fig_scat), lg=4)])\n",
    "            ])\n",
    "            \n",
    "    except Exception as e:\n",
    "        import traceback\n",
    "        return dbc.Alert([html.H5(\"Error Processing Data\", className=\"alert-heading\"), html.Pre(str(e)), html.Pre(traceback.format_exc())], color=\"danger\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f935e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8050/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x2c9d619da50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpretation Error: filters should not remove entries all entries - check encoder/decoder lengths and lags\n",
      "Interpretation Error: filters should not remove entries all entries - check encoder/decoder lengths and lags\n",
      "Interpretation Error: filters should not remove entries all entries - check encoder/decoder lengths and lags\n",
      "Interpretation Error: filters should not remove entries all entries - check encoder/decoder lengths and lags\n",
      "Interpretation Error: filters should not remove entries all entries - check encoder/decoder lengths and lags\n",
      "Interpretation Error: filters should not remove entries all entries - check encoder/decoder lengths and lags\n",
      "Interpretation Error: filters should not remove entries all entries - check encoder/decoder lengths and lags\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üí° Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "üí° Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "üí° Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "üí° Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "üí° Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    app.run(debug=True, port=8050)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tft",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
